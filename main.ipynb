{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data_col_list = data.columns.to_list()\n",
    "    x_col_list = data_col_list[:-1]\n",
    "    print(f\"Independent Values;\\n{x_col_list}\")\n",
    "\n",
    "    y_col = data_col_list[-1]\n",
    "    #Extract the independent variables (features) into matrix X\n",
    "    X = data[x_col_list].values\n",
    "\n",
    "    #Extract the dependent variable into vector Y\n",
    "    Y = data[y_col].values\n",
    "    print(f\"dependent Values;\\n{y_col}\")\n",
    "    return X, Y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X, Y, test_size=0.3, random_state=None):\n",
    "    \"\"\"\n",
    "    Split the data into training and test sets.\n",
    "\n",
    "    Args:\n",
    "    X (numpy.ndarray): The independent variables (features).\n",
    "    Y (numpy.ndarray): The dependent variable.\n",
    "    test_size (float): The proportion of data to include in the test split (default is 0.3).\n",
    "    random_state (int or None): Seed for random number generation (optional).\n",
    "\n",
    "    Returns:\n",
    "    X_train (numpy.ndarray): Training data for independent variables.\n",
    "    X_test (numpy.ndarray): Test data for independent variables.\n",
    "    Y_train (numpy.ndarray): Training data for the dependent variable.\n",
    "    Y_test (numpy.ndarray): Test data for the dependent variable.\n",
    "    \"\"\"\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(N_x, N_h, N_y):\n",
    "    \"\"\"\n",
    "    Initialize parameters (weights and biases) for a neural network with two layers.\n",
    "    \n",
    "    Arguments:\n",
    "    N_x -- Number of input features\n",
    "    N_h -- Number of hidden units in layer 1\n",
    "    N_y -- Number of output units in layer 2\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- A dictionary containing randomly initialized parameters:\n",
    "                    W1 -- Weight matrix of shape (N_h, N_x)\n",
    "                    b1 -- Bias vector of shape (N_h, 1)\n",
    "                    W2 -- Weight matrix of shape (N_y, N_h)\n",
    "                    b2 -- Bias vector of shape (N_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)  # Seed for reproducibility\n",
    "    \n",
    "    # Initialize weights and biases for layer 1\n",
    "    W1 = np.random.randn(N_h, N_x) * 0.01\n",
    "    b1 = np.zeros((N_h, 1))\n",
    "    \n",
    "    # Initialize weights and biases for layer 2\n",
    "    W2 = np.random.randn(N_y, N_h) * 0.01\n",
    "    b2 = np.zeros((N_y, 1))\n",
    "    \n",
    "    # Store the parameters in a dictionary\n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2\n",
    "    }\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid activation function for a given input.\n",
    "    \n",
    "    Arguments:\n",
    "    z -- Input value (can be a scalar or a NumPy array)\n",
    "    \n",
    "    Returns:\n",
    "    A -- Output of the sigmoid function, same shape as z\n",
    "    \"\"\"\n",
    "    A = 1 / (1 + np.exp(-z))\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\"\n",
    "    Compute the ReLU (Rectified Linear Unit) activation function for a given input.\n",
    "    \n",
    "    Arguments:\n",
    "    z -- Input value (can be a scalar or a NumPy array)\n",
    "    \n",
    "    Returns:\n",
    "    A -- Output of the ReLU function, same shape as z\n",
    "    \"\"\"\n",
    "    A = np.maximum(0, z)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_pass(X, parameters):\n",
    "    \"\"\"\n",
    "    Perform the forward pass in a two-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input data of shape (input_size, m), where m is the number of examples\n",
    "    parameters -- A dictionary containing the parameters:\n",
    "                    W1 -- Weight matrix of shape (hidden_size, input_size)\n",
    "                    b1 -- Bias vector of shape (hidden_size, 1)\n",
    "                    W2 -- Weight matrix of shape (output_size, hidden_size)\n",
    "                    b2 -- Bias vector of shape (output_size, 1)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second layer with shape (1, m)\n",
    "    cache -- A dictionary containing the intermediate results required for backpropagation:\n",
    "                Z1 -- The weighted sum of the first layer\n",
    "                A1 -- The activation of the first layer (ReLU)\n",
    "                Z2 -- The weighted sum of the second layer\n",
    "                A2 -- The activation of the second layer (sigmoid)\n",
    "    \"\"\"\n",
    "    # Retrieve parameters from the dictionary\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Forward propagation for layer 1 (ReLU activation)\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.maximum(0, Z1)  # ReLU activation\n",
    "    \n",
    "    # Forward propagation for layer 2 (sigmoid activation)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = 1 / (1 + np.exp(-Z2))  # Sigmoid activation\n",
    "    \n",
    "    # Store intermediate results in a cache\n",
    "    cache = {\n",
    "        \"Z1\": Z1,\n",
    "        \"A1\": A1,\n",
    "        \"Z2\": Z2,\n",
    "        \"A2\": A2  # Store A2 in the cache\n",
    "    }\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Function - Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cost(Y, Y_pred):\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy cost for binary classification.\n",
    "    \n",
    "    Arguments:\n",
    "    Y -- True labels (ground truth), shape (1, m)\n",
    "    Y_pred -- Predicted probabilities, shape (1, m)\n",
    "    \n",
    "    Returns:\n",
    "    cost -- Cross-entropy cost\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]  # Number of examples\n",
    "\n",
    "    # Compute the cross-entropy cost\n",
    "    cost = -np.sum(Y * np.log(Y_pred) + (1 - Y) * np.log(1 - Y_pred)) / m\n",
    "    \n",
    "    # Ensure the cost is a scalar value (not a NumPy array)\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backward_pass(X, Y, cache, parameters):\n",
    "    \"\"\"\n",
    "    Perform the backward pass to compute gradients of all parameters.\n",
    "\n",
    "    Arguments:\n",
    "    X -- Input data of shape (input_size, m)\n",
    "    Y -- True labels (ground truth) of shape (1, m)\n",
    "    cache -- A dictionary containing the intermediate results from the forward pass\n",
    "    parameters -- A dictionary containing the parameters:\n",
    "                    W1 -- Weight matrix of shape (hidden_size, input_size)\n",
    "                    b1 -- Bias vector of shape (hidden_size, 1)\n",
    "                    W2 -- Weight matrix of shape (output_size, hidden_size)\n",
    "                    b2 -- Bias vector of shape (output_size, 1)\n",
    "\n",
    "    Returns:\n",
    "    grads -- A dictionary containing the gradients of all parameters:\n",
    "                dW1 -- Gradient of W1\n",
    "                db1 -- Gradient of b1\n",
    "                dW2 -- Gradient of W2\n",
    "                db2 -- Gradient of b2\n",
    "    \"\"\"\n",
    "    m = X.shape[1]  # Number of examples\n",
    "\n",
    "    # Retrieve intermediate results from the cache\n",
    "    Z1 = cache[\"Z1\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    Z2 = cache[\"Z2\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "\n",
    "    # Compute the gradient of the cost with respect to A2\n",
    "    dA2 = - (Y / A2 - (1 - Y) / (1 - A2))\n",
    "\n",
    "    # Backpropagate through layer 2 (sigmoid activation)\n",
    "    dZ2 = dA2 * A2 * (1 - A2)\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    # Backpropagate through layer 1 (ReLU activation)\n",
    "    dA1 = np.dot(parameters[\"W2\"].T, dZ2)\n",
    "    dZ1 = dA1 * (A1 > 0)\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    # Store gradients in a dictionary\n",
    "    grads = {\n",
    "        \"dW1\": dW1,\n",
    "        \"db1\": db1,\n",
    "        \"dW2\": dW2,\n",
    "        \"db2\": db2\n",
    "    }\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train, X_test, Y_test, input_size, hidden_size, output_size, learning_rate, num_epochs):\n",
    "    \"\"\"\n",
    "    Train a two-layer neural network using gradient descent and calculate training and testing errors.\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training input data of shape (input_size, m_train)\n",
    "    Y_train -- Training true labels (ground truth) of shape (1, m_train)\n",
    "    X_test -- Testing input data of shape (input_size, m_test)\n",
    "    Y_test -- Testing true labels (ground truth) of shape (1, m_test)\n",
    "    input_size -- Number of input features\n",
    "    hidden_size -- Number of hidden units in layer 1\n",
    "    output_size -- Number of output units in layer 2\n",
    "    learning_rate -- Learning rate for gradient descent\n",
    "    num_epochs -- Number of training epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- A dictionary containing the trained parameters (weights and biases)\n",
    "    train_costs -- List of training cost values at each epoch\n",
    "    test_costs -- List of testing cost values at each epoch\n",
    "    \"\"\"\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    # Initialize lists to store cost values at each epoch\n",
    "    train_costs = []\n",
    "    test_costs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training forward pass to compute predictions and intermediate results\n",
    "        train_predictions, train_cache = forward_pass(X_train, parameters)\n",
    "\n",
    "        # Compute training cost\n",
    "        train_cost = compute_cost(Y_train, train_predictions)\n",
    "\n",
    "        # Backward pass for training data to compute gradients\n",
    "        train_grads = backward_pass(X_train, Y_train, train_cache, parameters)\n",
    "\n",
    "        # Update parameters for training data using gradient descent\n",
    "        parameters[\"W1\"] -= learning_rate * train_grads[\"dW1\"]\n",
    "        parameters[\"b1\"] -= learning_rate * train_grads[\"db1\"]\n",
    "        parameters[\"W2\"] -= learning_rate * train_grads[\"dW2\"]\n",
    "        parameters[\"b2\"] -= learning_rate * train_grads[\"db2\"]\n",
    "\n",
    "        # Testing forward pass to compute predictions and intermediate results\n",
    "        test_predictions, _ = forward_pass(X_test, parameters)\n",
    "\n",
    "        # Compute testing cost\n",
    "        test_cost = compute_cost(Y_test, test_predictions)\n",
    "\n",
    "        # Append the training and testing costs to their respective lists\n",
    "        train_costs.append(train_cost)\n",
    "        test_costs.append(test_cost)\n",
    "\n",
    "        # Print the cost for every 100 epochs (optional)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Training Cost = {train_cost}, Testing Cost = {test_cost}\")\n",
    "\n",
    "    return parameters, train_costs, test_costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent Values;\n",
      "['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
      "dependent Values;\n",
      "TenYearCHD\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'dataset/Heart_Disease.csv'\n",
    "X, Y = load_data(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_data(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_x = 15  # Number of input features\n",
    "N_h = 20 # Number of hidden units in layer 1\n",
    "N_y = 2  # Number of output units in layer 2\n",
    "lr = 0.0001\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Cost = 1.3577075340845104, Testing Cost = 1.3510269372226134\n",
      "Epoch 100: Training Cost = 0.9578016659869815, Testing Cost = 0.9500658734128805\n",
      "Epoch 200: Training Cost = 0.8897116521673942, Testing Cost = 0.8796491388033176\n",
      "Epoch 300: Training Cost = 0.8871695583281062, Testing Cost = 0.8764462058076953\n",
      "Epoch 400: Training Cost = 0.8867336838763153, Testing Cost = 0.875994590842423\n",
      "Epoch 500: Training Cost = 0.8863713586261306, Testing Cost = 0.8757663230456247\n",
      "Epoch 600: Training Cost = 0.8860618547897218, Testing Cost = 0.8755777106323166\n",
      "Epoch 700: Training Cost = 0.8857590979958987, Testing Cost = 0.8753952257999631\n",
      "Epoch 800: Training Cost = 0.8854560504454411, Testing Cost = 0.8752192433666056\n",
      "Epoch 900: Training Cost = 0.8851550962155134, Testing Cost = 0.8750428385391035\n"
     ]
    }
   ],
   "source": [
    "params, train_cost, test_cost = fit(\n",
    "    X_train = X_train.T,\n",
    "    Y_train = Y_train.reshape(1,-1),\n",
    "    X_test = X_test.T,\n",
    "    Y_test = Y_test.reshape(1,-1),\n",
    "    input_size = N_x,\n",
    "    hidden_size = N_h,\n",
    "    output_size = N_y,\n",
    "    learning_rate = lr,\n",
    "    num_epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an array of epoch numbers for the x-axis\n",
    "\n",
    "_epochs = range(len(train_cost))\n",
    "\n",
    "# Plot training and testing costs\n",
    "plt.plot(_epochs, train_cost, label='Training Cost', linewidth=2)\n",
    "plt.plot(_epochs, test_cost, label='Testing Cost', linewidth=2)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"plots/hidden_units:{N_h},lr:{lr}, epochs:{epochs}.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained parameters saved as Stroke_Prediction_2_layer_NN.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the filename for the pickle file\n",
    "params_filename = 'Stroke_Prediction_2_layer_NN.pkl'\n",
    "\n",
    "# Save the 'params' dictionary as a pickle file\n",
    "with open(params_filename, 'wb') as file:\n",
    "    pickle.dump(params, file)\n",
    "\n",
    "print(f'Trained parameters saved as {params_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the filename for the pickle file\n",
    "params_filename = 'Stroke_Prediction_2_layer_NN.pkl'\n",
    "\n",
    "# Load the parameters from the pickle file\n",
    "with open(params_filename, 'rb') as file:\n",
    "    loaded_params = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained neural network.\n",
    "\n",
    "    Arguments:\n",
    "    parameters -- A dictionary containing the trained parameters (weights and biases)\n",
    "    X -- Input data of shape (input_size, m)\n",
    "\n",
    "    Returns:\n",
    "    predictions -- Predicted output of shape (1, m)\n",
    "    \"\"\"\n",
    "    # Retrieve the parameters from the dictionary\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    # Perform the forward pass to compute predictions\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.maximum(0, Z1)  # ReLU activation\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    predictions = 1 / (1 + np.exp(-Z2))  # Sigmoid activation\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Input vector for prediction (shape: (input_size, m))\n",
    "input_vector = np.array([0, 63, 1, 0, 0, 0, 0, 0, 0, 205, 138, 71, 33.11, 60, 85]).reshape(-1, 1)\n",
    "\n",
    "# Make predictions using the loaded parameters\n",
    "predictions = predict(loaded_params, input_vector)\n",
    "\n",
    "# Define a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predictions to binary (0 or 1) based on the threshold\n",
    "binary_predictions = (predictions >= threshold).astype(int)\n",
    "\n",
    "print(binary_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82c4f50c58b45b2bacee999af6f1393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a182be98eecd4cd094afaaa0a65a4061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stroke_Prediction_2_layer_NN.pkl:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/sharoz/Stroke_Prediction_2_layer_NN/blob/main/model.pkl'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"Stroke_Prediction_2_layer_NN.pkl\",\n",
    "    path_in_repo=\"model.pkl\",\n",
    "    repo_id=\"sharoz/Stroke_Prediction_2_layer_NN\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
